{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 设置gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torchvision.datasets.CIFAR10('data', \n",
    "                                      train=True, \n",
    "                                      transform=torchvision.transforms.ToTensor(), # 将数据类型转化为Tensor\n",
    "                                      download=True)\n",
    "\n",
    "test_ds  = torchvision.datasets.CIFAR10('data', \n",
    "                                      train=False, \n",
    "                                      transform=torchvision.transforms.ToTensor(), # 将数据类型转化为Tensor\n",
    "                                      download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "批量读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, \n",
    "                                       batch_size=batch_size, \n",
    "                                       shuffle=True)\n",
    "\n",
    "test_dl  = torch.utils.data.DataLoader(test_ds, \n",
    "                                       batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取一个批次查看数据格式\n",
    "# 数据的shape为：[batch_size, channel, height, weight]\n",
    "# 其中batch_size为自己设定，channel，height和weight分别是图片的通道数，高度和宽度。\n",
    "imgs, labels = next(iter(train_dl))\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    " # 指定图片大小，图像大小为20宽、5高的绘图(单位为英寸inch)\n",
    "plt.figure(figsize=(20, 5)) \n",
    "for i, imgs in enumerate(imgs[:20]):\n",
    "    # 维度缩减\n",
    "    npimg = imgs.numpy().transpose((1, 2, 0))\n",
    "    # 将整个figure分成2行10列，绘制第i+1个子图。\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(npimg, cmap=plt.cm.binary)\n",
    "    plt.axis('off')\n",
    "    \n",
    "#plt.show()  如果你使用的是Pycharm编译器，请加上这行代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 CNN网络构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "num_classes = 10  # 图片的类别数\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 特征提取网络\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3)  # 第一层卷积,卷积核大小为3*3\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)  # 设置池化层，池化核大小为2*2\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3)  # 第二层卷积,卷积核大小为3*3\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)  # 第二层卷积,卷积核大小为3*3\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # 分类网络\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    # 前向传播\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印CNN模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "# 将模型转移到GPU中（我们模型运行均在GPU中进行）\n",
    "model = Model().to(device)\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()  # 创建损失函数\n",
    "learn_rate = 1e-1  # 学习率\n",
    "opt = torch.optim.SGD(model.parameters(), lr=learn_rate)\n",
    "lr_lambda = lambda epoch:1.0 if epoch<10 else np.math.exp(0.1*(10-epoch))\n",
    "torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练循环\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)  # 训练集的大小，一共60000张图片\n",
    "    num_batches = len(dataloader)   # 批次数目，1875（60000/32）\n",
    "\n",
    "    train_loss, train_acc = 0, 0  # 初始化训练损失和正确率\n",
    "    \n",
    "    for X, y in dataloader:  # 获取图片及其标签\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # 计算预测误差\n",
    "        pred = model(X)          # 网络输出\n",
    "        loss = loss_fn(pred, y)  # 计算网络输出和真实值之间的差距，targets为真实值，计算二者差值即为损失\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()  # grad属性归零\n",
    "        loss.backward()        # 反向传播\n",
    "        optimizer.step()       # 每一步自动更新\n",
    "        \n",
    "        # 记录acc与loss\n",
    "        train_acc  += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        train_loss += loss.item()\n",
    "            \n",
    "    train_acc  /= size\n",
    "    train_loss /= num_batches\n",
    "\n",
    "    return train_acc, train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test (dataloader, model, loss_fn):\n",
    "    size        = len(dataloader.dataset)  # 测试集的大小，一共10000张图片\n",
    "    num_batches = len(dataloader)          # 批次数目，313（10000/32=312.5，向上取整）\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # 当不进行训练时，停止梯度更新，节省计算内存消耗\n",
    "    with torch.no_grad():\n",
    "        for imgs, target in dataloader:\n",
    "            imgs, target = imgs.to(device), target.to(device)\n",
    "            \n",
    "            # 计算loss\n",
    "            target_pred = model(imgs)\n",
    "            loss        = loss_fn(target_pred, target)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc  += (target_pred.argmax(1) == target).type(torch.float).sum().item()\n",
    "\n",
    "    test_acc  /= size\n",
    "    test_loss /= num_batches\n",
    "\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs     = 10\n",
    "train_loss = []\n",
    "train_acc  = []\n",
    "test_loss  = []\n",
    "test_acc   = []\n",
    "learn_rate = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_train_acc, epoch_train_loss = train(train_dl, model, loss_fn, opt)\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_test_acc, epoch_test_loss = test(test_dl, model, loss_fn)\n",
    "    \n",
    "    train_acc.append(epoch_train_acc)\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    test_acc.append(epoch_test_acc)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    \n",
    "    template = ('Epoch:{:2d}, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%，Test_loss:{:.3f}')\n",
    "    print(template.format(epoch+1, epoch_train_acc*100, epoch_train_loss, epoch_test_acc*100, epoch_test_loss))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 训练结果评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#隐藏警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")               #忽略警告信息\n",
    "plt.rcParams['font.sans-serif']    = ['SimHei'] # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False      # 用来正常显示负号\n",
    "plt.rcParams['figure.dpi']         = 100        #分辨率\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 3, 1)\n",
    "\n",
    "plt.plot(epochs_range, train_acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, test_acc, label='Test Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs_range, train_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, test_loss, label='Test Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
